import subprocess
import time
import os

HR_PROJECT_PATH = "C:/Users/texcl/friend_env/hr_demo"
FRONTEND_PATH = os.path.join(HR_PROJECT_PATH, "frontend")
OLLAMA_PATH = "C:/Users/texcl/AppData/Local/Programs/Ollama"

def run_ollama():
    print("âœ… ì¸ì‚¬ê³¼ì¥A ì„œë²„ ì‹¤í–‰ ì¤‘... (http://localhost:11434)")
    return subprocess.Popen(
        ['ollama', 'serve'],
        cwd=OLLAMA_PATH,
        stdout=subprocess.DEVNULL,
        stderr=subprocess.DEVNULL
    )

def run_backend():
    print("âœ… ë°±ì—”ë“œ ì„œë²„ ì‹¤í–‰ ì¤‘... (http://localhost:8000)")
    return subprocess.Popen(
        ['uvicorn', 'main:app', '--reload', '--host', '127.0.0.1'],
        cwd=HR_PROJECT_PATH
    )

def run_frontend():
    print("âœ… í”„ë¡ íŠ¸ì—”ë“œ ì•± ì‹¤í–‰ ì¤‘... (http://localhost:3000)")
    return subprocess.Popen(
        ['cmd', '/c', 'npm start'],
        cwd=FRONTEND_PATH
    )

def main():
    print("ğŸš€ ì¸ì‚¬ê³¼ì¥A ì‹œìŠ¤í…œ ì‹œì‘ ì¤‘...")

    ollama_process = run_ollama()
    time.sleep(5)

    backend_process = run_backend()
    time.sleep(5)

    frontend_process = run_frontend()

    print("\nğŸŒ ë¸Œë¼ìš°ì €ë¥¼ ì—´ë ¤ë©´ http://localhost:3000 ìœ¼ë¡œ ì ‘ì†í•˜ì„¸ìš”.")

    try:
        backend_process.wait()
        frontend_process.wait()
        ollama_process.wait()
    except KeyboardInterrupt:
        print("\nğŸ›‘ ì‹¤í–‰ ì¤‘ë‹¨: ì„œë²„ ì¢…ë£Œ ì¤‘...")
        backend_process.terminate()
        frontend_process.terminate()
        ollama_process.terminate()

if __name__ == '__main__':
    main()
